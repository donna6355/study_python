{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29d0370-2113-4afa-8f43-4ff8fd84d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.21.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/donna/.local/pipx/venvs/notebook/lib/python3.14/site-packages (from openai) (4.12.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/donna/.local/pipx/venvs/notebook/lib/python3.14/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.13.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: sniffio in /Users/donna/.local/pipx/venvs/notebook/lib/python3.14/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/donna/.local/pipx/venvs/notebook/lib/python3.14/site-packages (from openai) (4.67.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/donna/.local/pipx/venvs/notebook/lib/python3.14/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/donna/.local/pipx/venvs/notebook/lib/python3.14/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/donna/.local/pipx/venvs/notebook/lib/python3.14/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/donna/.local/pipx/venvs/notebook/lib/python3.14/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/donna/.local/pipx/venvs/notebook/lib/python3.14/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.5-cp314-cp314-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-2.21.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.13.0-cp314-cp314-macosx_11_0_arm64.whl (318 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp314-cp314-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, jiter, distro, annotated-types, pydantic, openai\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [openai]━━━━\u001b[0m \u001b[32m6/7\u001b[0m [openai]pydantic]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.13.0 openai-2.21.0 pydantic-2.12.5 pydantic-core-2.41.5 typing-inspection-0.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/donna/.local/pipx/venvs/notebook/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e83aeb4-f484-4a50-99f7-91686b537cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "GPT_KEY = 'sk-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4404292d-c2d2-4a55-a8d2-fa78298985e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key = GPT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d740c04b-4e14-4094-a0ae-b9cbd998c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        { \"role\":\"system\", \"content\":\"You are a Professor majoring physics.\"}, \n",
    "        {'role':'user', 'content':'why is the ice slippery'}\n",
    "    ],\n",
    "    stream = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e17172f6-1fb5-4464-aabf-c97e0a9036ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slipperiness of ice is due to a thin layer of water that forms on its surface. When pressure is applied to the ice, such as from the weight of a person's foot, the ice melts slightly under that pressure and creates a thin layer of liquid water. This layer of water significantly reduces the friction between the ice and any object moving across it, making it slippery. This is why ice can be so slippery, especially at temperatures close to its melting point."
     ]
    }
   ],
   "source": [
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7e6514-8214-48e3-af9a-72861c9611b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a great question! Ice is slippery because when you walk on it, the pressure from your weight creates a thin layer of water on top of the ice. This water acts like a lubricant, making it more slippery to walk on. So, the combination of the ice melting slightly under pressure and creating a thin layer of water is what makes ice slippery. It's important to walk carefully on icy surfaces to avoid slipping and falling."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        { \"role\":\"system\", \"content\":\"You are teaching 5 years old kid\"}, \n",
    "        {'role':'user', 'content':'why is the ice slippery'}\n",
    "    ],\n",
    "    stream = True\n",
    ")\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc5eec35-30bc-404b-902c-0eb26e6949bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I cannot assist with that question."
     ]
    }
   ],
   "source": [
    "#RAG\n",
    "question = 'Among Jack, John, and Jane, who is the merderer?'\n",
    "stream = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        { \"role\":\"system\", \"content\":\"You are a detective\"}, \n",
    "        {'role':'user', 'content':question }\n",
    "    ],\n",
    "    stream = True\n",
    ")\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4755f53f-d9cf-4450-aa3d-ede92cf7644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information available, Jack is the murderer."
     ]
    }
   ],
   "source": [
    "retrieve = {\n",
    "    \"Jack\": \" In our case, Jack was the murderer.\",\n",
    "    \"John\":\"In our case, John is innocent.\",\n",
    "    \"Jane\":\"In our case, Jane is innocent.\",\n",
    "}\n",
    "#json, pdf, excel all format is available, json is the most ideal format\n",
    "\n",
    "#generally based on similarity, this is only for test demonstration\n",
    "def search_doc(question):\n",
    "    for key in retrieve:\n",
    "        if key in question:\n",
    "            return retrieve[key]\n",
    "    return \"No relevant information found.\"\n",
    "    \n",
    "question = 'Among Jack, John, and Jane, who is the merderer?'\n",
    "stream = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        { \"role\":\"system\", \"content\":\"You are a detective\"}, \n",
    "        {'role':'user', 'content':question },\n",
    "        { \"role\":\"system\", \"content\":f\"search result: {search_doc(question)}\"}\n",
    "    ],\n",
    "    stream = True\n",
    ")\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fe1388-0294-41c6-a4f3-f2095127caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine Tuning\n",
    "#이렇게 질문하면 이렇게 답해, 10개 이상의 데이터가 필요\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf0a4b-e5d6-41b9-b57b-f40cb67808d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Ronaldo, Messi, and Neymar, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Messi\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Ronaldo, Neymar, and Benzema, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Ronaldo\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Neymar, Benzema, and Lewandowski, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Neymar\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Benzema, Kane, and Lewandowski, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Lewandowski\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Benzema, Kane, and Suarez, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Benzema\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Modric, Kane, and Suarez, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Modric\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Henry, Kane, and Suarez, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Henry\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Bale, Kane, and Suarez, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Suarez\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Bale, Kane, and Salah, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Bale\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Son, Kane, and Salah, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Kane\"}\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38d347-cdcc-4ab7-a80e-0ff41299bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('finetuning_data.jsonl', 'w', encoding='utf-8-sig') as json_file:\n",
    "    for item in data:\n",
    "        json_file.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "uploaded_file = client.files.create(file=open(\"finetuning_data.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
    "file_id = uploaded_file.id\n",
    "\n",
    "fine_tune_job = client.fine_tuning.jobs.create(training_file=file_id, model=\"gpt-3.5-turbo\")\n",
    "fine_tune_job_id = fine_tune_job.id\n",
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tune_job_id, limit=10)\n",
    "for event in events.data:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294da524-b0dc-4c36-9eb1-23097b85880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업로드 상태 확인\n",
    "fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tune_job_id)\n",
    "print(fine_tune_job.status)  # 'succeeded' 또는 'failed'\n",
    "fine_tuned_model_id = fine_tune_job.fine_tuned_model  # 파인튜닝된 모델의 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f009075-f126-4cd3-946d-a90f6ddf2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tune_job_id, limit=10)\n",
    "for event in events.data:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d738b2-3325-4f41-bda3-1a8493d9a6ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m stream = \u001b[43mclient\u001b[49m.chat.completions.create(\n\u001b[32m      2\u001b[39m     model= \u001b[33m\"\u001b[39m\u001b[33mft:gpt-3.5-turbo-0125:personal::A3WDgJPH\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     messages=[\n\u001b[32m      4\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33mYou are a football scout.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m      5\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33mAmong Messi, Maradona, and Pele, who is the best?\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m      6\u001b[39m     ],\n\u001b[32m      7\u001b[39m     stream=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(chunk.choices[\u001b[32m0\u001b[39m].delta.content \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model= \"ft:gpt-3.5-turbo-0125:personal::A3WDgJPH\",\n",
    "    messages=[\n",
    "        {\"role\" : \"system\", \"content\" : \"You are a football scout.\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"Among Messi, Maradona, and Pele, who is the best?\"}\n",
    "    ],\n",
    "    stream=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
